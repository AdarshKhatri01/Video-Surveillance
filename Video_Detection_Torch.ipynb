{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88d44fe-2c61-463d-86ba-9ae11aebb0eb",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44d4a8b-8505-45bc-90eb-5828d4c9ff65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63d2a5a-eb7c-481c-93d4-d36412faacac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VRAM Clear Karne Ke Liye Ye Commands Run Kar\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b94d86-da62-4fd0-bfc4-70ac984b6740",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7a236e-483b-487b-a298-23b1e9a10404",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"dataset\"\n",
    "NON_VIOLENCE = \"NonViolence\"\n",
    "VIOLENCE = \"Violence\"\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e93213-00dd-4db8-819c-cd5e47ca58c5",
   "metadata": {},
   "source": [
    "### Dataset Loader (Video to Frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53edef-1954-43a2-92f3-aaa0da5b0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, sequence_length=20, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.transform = transform\n",
    "        self.video_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Get all video file paths and labels\n",
    "        for label, category in enumerate([NON_VIOLENCE, VIOLENCE]):\n",
    "            folder_path = os.path.join(root_dir, category, \"RLVS\")\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(\".mp4\"):\n",
    "                    self.video_paths.append(os.path.join(folder_path, file))\n",
    "                    self.labels.append(label)  # 0 = NonViolence, 1 = Violence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (224, 224))  # Resize\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Fix sequence length\n",
    "        if len(frames) > self.sequence_length:\n",
    "            frames = frames[:self.sequence_length]\n",
    "        else:\n",
    "            while len(frames) < self.sequence_length:\n",
    "                frames.append(frames[-1])\n",
    "\n",
    "        frames = torch.stack(frames)  # Convert list to tensor\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f8056-4fa5-4d4d-aa2e-d68895cc595d",
   "metadata": {},
   "source": [
    "### Transformations & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac75fc00-e451-4315-bf50-2c4967ffd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize for CNN/LSTM\n",
    "])\n",
    "\n",
    "dataset = VideoDataset(root_dir=DATASET, sequence_length=20, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ac95f-3c93-4496-8d8a-79e74b298fcd",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc51ab9d-fe9e-4fdb-a295-df9acb55d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, hidden_size=64, num_layers=2):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "        \n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: 112x112 -> 56x56\n",
    "            \n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: 56x56 -> 28x28\n",
    "\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: 28x28 -> 14x14\n",
    "#         )\n",
    "        \n",
    "#         self.lstm = nn.LSTM(128 * 14 * 14, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(hidden_size, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 1)  # Last layer\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, seq_len, c, h, w = x.shape\n",
    "#         x = x.view(batch_size * seq_len, c, h, w)\n",
    "#         x = self.conv(x)\n",
    "#         x = x.view(batch_size, seq_len, -1)  \n",
    "#         x, _ = self.lstm(x)\n",
    "#         x = self.fc(x[:, -1, :])\n",
    "#         return x  # No sigmoid here, use BCEWithLogitsLoss\n",
    "\n",
    "# model = LSTMModel().to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6718039a-b7e2-4c30-9893-ce919f9b6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, hidden_size=64, num_layers=2):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  \n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # 112x112 -> 56x56\n",
    "            \n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2)  # 56x56 -> 28x28\n",
    "#         )\n",
    "        \n",
    "#         self.lstm_input_size = 128 * 28 * 28  # CNN output size\n",
    "#         self.lstm = nn.LSTM(self.lstm_input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "#         self.fc = nn.Linear(hidden_size, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, seq_len, c, h, w = x.shape  \n",
    "\n",
    "#         x = x.view(batch_size * seq_len, c, h, w)  # Reshape for CNN\n",
    "#         x = self.conv(x)  # CNN Output: (batch_size * seq_len, 128, 28, 28)\n",
    "        \n",
    "#         x = x.view(batch_size, seq_len, -1)  # Reshape for LSTM: (batch, seq, 128*28*28)\n",
    "#         x, _ = self.lstm(x)  \n",
    "        \n",
    "#         x = self.fc(x[:, -1, :])  # Last timestep ka output\n",
    "#         return self.sigmoid(x)\n",
    "\n",
    "# # Model initialization\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = LSTMModel().to(device)\n",
    "\n",
    "# # Loss function & optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Dummy input test\n",
    "# dummy_input = torch.randn(1, 8, 3, 112, 112).to(device)\n",
    "# output = model(dummy_input)\n",
    "# print(output.shape)  # Expected: torch.Size([1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e01d4a5-2141-4ba3-903c-cc1090ea3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------WORKING-----------------------------------\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.lstm_input_size = 128 * 28 * 28  # ✅ Corrected LSTM input size\n",
    "        self.lstm_hidden_size = 256\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=self.lstm_hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)  # ✅ Added Dropout\n",
    "        self.fc = nn.Linear(self.lstm_hidden_size, 1)  \n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, C, H, W = x.shape  \n",
    "        x = x.view(batch_size * seq_len, C, H, W)  \n",
    "\n",
    "        x = self.conv(x)  \n",
    "        # print(f\"CNN output shape: {x.shape}\")  # 🛠️ Debugging output\n",
    "\n",
    "        x = x.view(batch_size, seq_len, -1)  \n",
    "        # print(f\"LSTM input shape: {x.shape}\")  # 🛠️ Debugging output\n",
    "\n",
    "        x, _ = self.lstm(x)  \n",
    "        x = self.dropout(x) \n",
    "        x = self.fc(x[:, -1, :])  \n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dc3b37-adaf-4d2b-8f1f-edea6289dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: (batch*seq, 64, 56, 56)\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2)   # Output: (batch*seq, 128, 28, 28)\n",
    "#         )\n",
    "        \n",
    "#         self.lstm_input_size = 128 * 28 * 28\n",
    "#         self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=512, num_layers=2, batch_first=True)\n",
    "\n",
    "#         self.fc = nn.Linear(512, 1)  \n",
    "#         # self.sigmoid = nn.Sigmoid()  # Remove this if using BCEWithLogitsLoss\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         batch_size, seq_len, C, H, W = x.shape\n",
    "#         x = x.view(batch_size * seq_len, C, H, W)  # Flatten for CNN\n",
    "#         x = self.conv(x)  # Output: (batch*seq, 128, 28, 28)\n",
    "#         x = x.view(batch_size, seq_len, -1)  # Reshape for LSTM\n",
    "#         x, _ = self.lstm(x)  \n",
    "#         x = self.fc(x[:, -1, :])  # Last timestep output\n",
    "#         return x  # Return logits directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c72cf9-f74c-4d12-a8bf-890d36c47d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: (batch*seq, 64, 56, 56)\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # Output: (batch*seq, 128, 28, 28)\n",
    "#             nn.BatchNorm2d(128)   # ADDED BATCHNORM\n",
    "#         )\n",
    "        \n",
    "#         self.lstm_input_size = 128 * 28 * 28\n",
    "#         self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=512, num_layers=2, batch_first=True)\n",
    "\n",
    "#         self.fc = nn.Linear(512, 1)\n",
    "#         # self.sigmoid = nn.Sigmoid()  # Remove this if using BCEWithLogitsLoss\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         batch_size, seq_len, C, H, W = x.shape\n",
    "#         x = x.view(batch_size * seq_len, C, H, W)  # Flatten for CNN\n",
    "#         x = self.conv(x)  # Output: (batch*seq, 128, 28, 28)\n",
    "#         x = x.view(batch_size, seq_len, -1)  # Reshape for LSTM\n",
    "#         x, _ = self.lstm(x)  \n",
    "#         x = self.fc(x[:, -1, :])  # Last timestep output\n",
    "#         return x  # Return logits directly\n",
    "\n",
    "# # Xavier Initialization\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "#         nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf86598-3ca5-4829-8b7d-5ebb1dcec86e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc92cf9-018f-4cf8-8ce4-dbfbe8079fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Batch [0/2951], Loss: 0.5370\n",
      "Epoch [1/5], Batch [10/2951], Loss: 0.4592\n",
      "Epoch [1/5], Batch [20/2951], Loss: 0.9592\n",
      "Epoch [1/5], Batch [30/2951], Loss: 0.9850\n",
      "Epoch [1/5], Batch [40/2951], Loss: 1.0767\n",
      "Epoch [1/5], Batch [50/2951], Loss: 0.9535\n",
      "Epoch [1/5], Batch [60/2951], Loss: 1.0542\n",
      "Epoch [1/5], Batch [70/2951], Loss: 0.9852\n",
      "Epoch [1/5], Batch [80/2951], Loss: 0.9027\n",
      "Epoch [1/5], Batch [90/2951], Loss: 0.4489\n",
      "Epoch [1/5], Batch [100/2951], Loss: 0.9773\n",
      "Epoch [1/5], Batch [110/2951], Loss: 0.9938\n",
      "Epoch [1/5], Batch [120/2951], Loss: 0.5563\n",
      "Epoch [1/5], Batch [130/2951], Loss: 0.4749\n",
      "Epoch [1/5], Batch [140/2951], Loss: 0.8351\n",
      "Epoch [1/5], Batch [150/2951], Loss: 0.8665\n",
      "Epoch [1/5], Batch [160/2951], Loss: 0.9533\n",
      "Epoch [1/5], Batch [170/2951], Loss: 0.4897\n",
      "Epoch [1/5], Batch [180/2951], Loss: 0.5045\n",
      "Epoch [1/5], Batch [190/2951], Loss: 0.4783\n",
      "Epoch [1/5], Batch [200/2951], Loss: 1.0369\n",
      "Epoch [1/5], Batch [210/2951], Loss: 0.4579\n",
      "Epoch [1/5], Batch [220/2951], Loss: 0.8973\n",
      "Epoch [1/5], Batch [230/2951], Loss: 1.0449\n",
      "Epoch [1/5], Batch [240/2951], Loss: 0.9033\n",
      "Epoch [1/5], Batch [250/2951], Loss: 0.9064\n",
      "Epoch [1/5], Batch [260/2951], Loss: 0.4653\n",
      "Epoch [1/5], Batch [270/2951], Loss: 0.9134\n",
      "Epoch [1/5], Batch [280/2951], Loss: 0.4233\n",
      "Epoch [1/5], Batch [290/2951], Loss: 0.8723\n",
      "Epoch [1/5], Batch [300/2951], Loss: 0.9347\n",
      "Epoch [1/5], Batch [310/2951], Loss: 0.9681\n",
      "Epoch [1/5], Batch [320/2951], Loss: 1.0348\n",
      "Epoch [1/5], Batch [330/2951], Loss: 0.4155\n",
      "Epoch [1/5], Batch [340/2951], Loss: 0.8987\n",
      "Epoch [1/5], Batch [350/2951], Loss: 0.8628\n",
      "Epoch [1/5], Batch [360/2951], Loss: 0.8751\n",
      "Epoch [1/5], Batch [370/2951], Loss: 0.4614\n",
      "Epoch [1/5], Batch [380/2951], Loss: 0.4780\n",
      "Epoch [1/5], Batch [390/2951], Loss: 0.9389\n",
      "Epoch [1/5], Batch [400/2951], Loss: 0.4780\n",
      "Epoch [1/5], Batch [410/2951], Loss: 0.8631\n",
      "Epoch [1/5], Batch [420/2951], Loss: 0.9918\n",
      "Epoch [1/5], Batch [430/2951], Loss: 0.8696\n",
      "Epoch [1/5], Batch [440/2951], Loss: 0.4758\n",
      "Epoch [1/5], Batch [450/2951], Loss: 0.8949\n",
      "Epoch [1/5], Batch [460/2951], Loss: 0.4707\n",
      "Epoch [1/5], Batch [470/2951], Loss: 0.5403\n",
      "Epoch [1/5], Batch [480/2951], Loss: 0.4824\n",
      "Epoch [1/5], Batch [490/2951], Loss: 0.3801\n",
      "Epoch [1/5], Batch [500/2951], Loss: 0.8817\n",
      "Epoch [1/5], Batch [510/2951], Loss: 0.4413\n",
      "Epoch [1/5], Batch [520/2951], Loss: 0.8821\n",
      "Epoch [1/5], Batch [530/2951], Loss: 0.4449\n",
      "Epoch [1/5], Batch [540/2951], Loss: 0.7970\n",
      "Epoch [1/5], Batch [550/2951], Loss: 0.8701\n",
      "Epoch [1/5], Batch [560/2951], Loss: 0.5217\n",
      "Epoch [1/5], Batch [570/2951], Loss: 0.5094\n",
      "Epoch [1/5], Batch [580/2951], Loss: 0.4653\n",
      "Epoch [1/5], Batch [590/2951], Loss: 0.8779\n",
      "Epoch [1/5], Batch [600/2951], Loss: 0.9126\n",
      "Epoch [1/5], Batch [610/2951], Loss: 0.4197\n",
      "Epoch [1/5], Batch [620/2951], Loss: 1.0997\n",
      "Epoch [1/5], Batch [630/2951], Loss: 0.8613\n",
      "Epoch [1/5], Batch [640/2951], Loss: 0.4289\n",
      "Epoch [1/5], Batch [650/2951], Loss: 0.9066\n",
      "Epoch [1/5], Batch [660/2951], Loss: 0.8964\n",
      "Epoch [1/5], Batch [670/2951], Loss: 0.8190\n",
      "Epoch [1/5], Batch [680/2951], Loss: 0.4283\n",
      "Epoch [1/5], Batch [690/2951], Loss: 0.4671\n",
      "Epoch [1/5], Batch [700/2951], Loss: 0.4156\n",
      "Epoch [1/5], Batch [710/2951], Loss: 0.5114\n",
      "Epoch [1/5], Batch [720/2951], Loss: 0.9084\n",
      "Epoch [1/5], Batch [730/2951], Loss: 0.5362\n",
      "Epoch [1/5], Batch [740/2951], Loss: 0.8468\n",
      "Epoch [1/5], Batch [750/2951], Loss: 0.8298\n",
      "Epoch [1/5], Batch [760/2951], Loss: 0.5139\n",
      "Epoch [1/5], Batch [770/2951], Loss: 0.5287\n",
      "Epoch [1/5], Batch [780/2951], Loss: 0.5232\n",
      "Epoch [1/5], Batch [790/2951], Loss: 0.4693\n",
      "Epoch [1/5], Batch [800/2951], Loss: 0.9226\n",
      "Epoch [1/5], Batch [810/2951], Loss: 0.8034\n",
      "Epoch [1/5], Batch [820/2951], Loss: 0.8118\n",
      "Epoch [1/5], Batch [830/2951], Loss: 0.9702\n",
      "Epoch [1/5], Batch [840/2951], Loss: 0.5603\n",
      "Epoch [1/5], Batch [850/2951], Loss: 0.8610\n",
      "Epoch [1/5], Batch [860/2951], Loss: 0.8663\n",
      "Epoch [1/5], Batch [870/2951], Loss: 0.8208\n",
      "Epoch [1/5], Batch [880/2951], Loss: 0.4294\n",
      "Epoch [1/5], Batch [890/2951], Loss: 0.8685\n",
      "Epoch [1/5], Batch [900/2951], Loss: 0.8497\n",
      "Epoch [1/5], Batch [910/2951], Loss: 1.0787\n",
      "Epoch [1/5], Batch [920/2951], Loss: 0.3841\n",
      "Epoch [1/5], Batch [930/2951], Loss: 1.0486\n",
      "Epoch [1/5], Batch [940/2951], Loss: 0.4967\n",
      "Epoch [1/5], Batch [950/2951], Loss: 0.4496\n",
      "Epoch [1/5], Batch [960/2951], Loss: 0.9562\n",
      "Epoch [1/5], Batch [970/2951], Loss: 0.4770\n",
      "Epoch [1/5], Batch [980/2951], Loss: 0.4613\n",
      "Epoch [1/5], Batch [990/2951], Loss: 0.5419\n",
      "Epoch [1/5], Batch [1000/2951], Loss: 0.8375\n",
      "Epoch [1/5], Batch [1010/2951], Loss: 0.8631\n",
      "Epoch [1/5], Batch [1020/2951], Loss: 0.9470\n",
      "Epoch [1/5], Batch [1030/2951], Loss: 0.8363\n",
      "Epoch [1/5], Batch [1040/2951], Loss: 0.4686\n",
      "Epoch [1/5], Batch [1050/2951], Loss: 0.9661\n",
      "Epoch [1/5], Batch [1060/2951], Loss: 0.8592\n",
      "Epoch [1/5], Batch [1070/2951], Loss: 0.8606\n",
      "Epoch [1/5], Batch [1080/2951], Loss: 0.5836\n",
      "Epoch [1/5], Batch [1090/2951], Loss: 0.8412\n",
      "Epoch [1/5], Batch [1100/2951], Loss: 0.9018\n",
      "Epoch [1/5], Batch [1110/2951], Loss: 0.9586\n",
      "Epoch [1/5], Batch [1120/2951], Loss: 0.5406\n",
      "Epoch [1/5], Batch [1130/2951], Loss: 1.0279\n",
      "Epoch [1/5], Batch [1140/2951], Loss: 0.4706\n",
      "Epoch [1/5], Batch [1150/2951], Loss: 0.8177\n",
      "Epoch [1/5], Batch [1160/2951], Loss: 0.4938\n",
      "Epoch [1/5], Batch [1170/2951], Loss: 0.9508\n",
      "Epoch [1/5], Batch [1180/2951], Loss: 0.8009\n",
      "Epoch [1/5], Batch [1190/2951], Loss: 0.5421\n",
      "Epoch [1/5], Batch [1200/2951], Loss: 0.7718\n",
      "Epoch [1/5], Batch [1210/2951], Loss: 0.9144\n",
      "Epoch [1/5], Batch [1220/2951], Loss: 0.4937\n",
      "Epoch [1/5], Batch [1230/2951], Loss: 0.4001\n",
      "Epoch [1/5], Batch [1240/2951], Loss: 0.5613\n",
      "Epoch [1/5], Batch [1250/2951], Loss: 0.5115\n",
      "Epoch [1/5], Batch [1260/2951], Loss: 0.9472\n",
      "Epoch [1/5], Batch [1270/2951], Loss: 0.4283\n",
      "Epoch [1/5], Batch [1280/2951], Loss: 0.5543\n",
      "Epoch [1/5], Batch [1290/2951], Loss: 0.9779\n",
      "Epoch [1/5], Batch [1300/2951], Loss: 0.4278\n",
      "Epoch [1/5], Batch [1310/2951], Loss: 0.6057\n",
      "Epoch [1/5], Batch [1320/2951], Loss: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x565371d15bc0] mb_type 104 in P slice too large at 98 31\n",
      "[h264 @ 0x565371d15bc0] error while decoding MB 98 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Batch [1330/2951], Loss: 0.9655\n",
      "Epoch [1/5], Batch [1340/2951], Loss: 0.5363\n",
      "Epoch [1/5], Batch [1350/2951], Loss: 0.4182\n",
      "Epoch [1/5], Batch [1360/2951], Loss: 0.8977\n",
      "Epoch [1/5], Batch [1370/2951], Loss: 0.3976\n",
      "Epoch [1/5], Batch [1380/2951], Loss: 0.4649\n",
      "Epoch [1/5], Batch [1390/2951], Loss: 0.5093\n",
      "Epoch [1/5], Batch [1400/2951], Loss: 0.7994\n",
      "Epoch [1/5], Batch [1410/2951], Loss: 0.4649\n",
      "Epoch [1/5], Batch [1420/2951], Loss: 0.5070\n",
      "Epoch [1/5], Batch [1430/2951], Loss: 0.5733\n",
      "Epoch [1/5], Batch [1440/2951], Loss: 0.7801\n",
      "Epoch [1/5], Batch [1450/2951], Loss: 0.4585\n",
      "Epoch [1/5], Batch [1460/2951], Loss: 0.8105\n",
      "Epoch [1/5], Batch [1470/2951], Loss: 0.9014\n",
      "Epoch [1/5], Batch [1480/2951], Loss: 0.7522\n",
      "Epoch [1/5], Batch [1490/2951], Loss: 0.4563\n",
      "Epoch [1/5], Batch [1500/2951], Loss: 0.4760\n",
      "Epoch [1/5], Batch [1510/2951], Loss: 0.9267\n",
      "Epoch [1/5], Batch [1520/2951], Loss: 0.9792\n",
      "Epoch [1/5], Batch [1530/2951], Loss: 0.9574\n",
      "Epoch [1/5], Batch [1540/2951], Loss: 0.8660\n",
      "Epoch [1/5], Batch [1550/2951], Loss: 0.5723\n",
      "Epoch [1/5], Batch [1560/2951], Loss: 0.4683\n",
      "Epoch [1/5], Batch [1570/2951], Loss: 0.4618\n",
      "Epoch [1/5], Batch [1580/2951], Loss: 0.5763\n",
      "Epoch [1/5], Batch [1590/2951], Loss: 0.9774\n",
      "Epoch [1/5], Batch [1600/2951], Loss: 0.4386\n",
      "Epoch [1/5], Batch [1610/2951], Loss: 0.7498\n",
      "Epoch [1/5], Batch [1620/2951], Loss: 0.7647\n",
      "Epoch [1/5], Batch [1630/2951], Loss: 0.9292\n",
      "Epoch [1/5], Batch [1640/2951], Loss: 0.4181\n",
      "Epoch [1/5], Batch [1650/2951], Loss: 0.4170\n",
      "Epoch [1/5], Batch [1660/2951], Loss: 0.5652\n",
      "Epoch [1/5], Batch [1670/2951], Loss: 0.7993\n",
      "Epoch [1/5], Batch [1680/2951], Loss: 0.9575\n",
      "Epoch [1/5], Batch [1690/2951], Loss: 0.8289\n",
      "Epoch [1/5], Batch [1700/2951], Loss: 0.8866\n",
      "Epoch [1/5], Batch [1710/2951], Loss: 0.3978\n",
      "Epoch [1/5], Batch [1720/2951], Loss: 0.7637\n",
      "Epoch [1/5], Batch [1730/2951], Loss: 0.4302\n",
      "Epoch [1/5], Batch [1740/2951], Loss: 0.7781\n",
      "Epoch [1/5], Batch [1750/2951], Loss: 0.5936\n",
      "Epoch [1/5], Batch [1760/2951], Loss: 0.3983\n",
      "Epoch [1/5], Batch [1770/2951], Loss: 0.4144\n",
      "Epoch [1/5], Batch [1780/2951], Loss: 0.4701\n",
      "Epoch [1/5], Batch [1790/2951], Loss: 0.7786\n",
      "Epoch [1/5], Batch [1800/2951], Loss: 0.5290\n",
      "Epoch [1/5], Batch [1810/2951], Loss: 0.7488\n",
      "Epoch [1/5], Batch [1820/2951], Loss: 0.6158\n",
      "Epoch [1/5], Batch [1830/2951], Loss: 0.7505\n",
      "Epoch [1/5], Batch [1840/2951], Loss: 0.9014\n",
      "Epoch [1/5], Batch [1850/2951], Loss: 0.8386\n",
      "Epoch [1/5], Batch [1860/2951], Loss: 0.7490\n",
      "Epoch [1/5], Batch [1870/2951], Loss: 0.9920\n",
      "Epoch [1/5], Batch [1880/2951], Loss: 0.6292\n",
      "Epoch [1/5], Batch [1890/2951], Loss: 0.5186\n",
      "Epoch [1/5], Batch [1900/2951], Loss: 0.7759\n",
      "Epoch [1/5], Batch [1910/2951], Loss: 0.4593\n",
      "Epoch [1/5], Batch [1920/2951], Loss: 0.4922\n",
      "Epoch [1/5], Batch [1930/2951], Loss: 0.3882\n",
      "Epoch [1/5], Batch [1940/2951], Loss: 0.7502\n",
      "Epoch [1/5], Batch [1950/2951], Loss: 0.4428\n",
      "Epoch [1/5], Batch [1960/2951], Loss: 0.5157\n",
      "Epoch [1/5], Batch [1970/2951], Loss: 0.7714\n",
      "Epoch [1/5], Batch [1980/2951], Loss: 0.8460\n",
      "Epoch [1/5], Batch [1990/2951], Loss: 1.0285\n",
      "Epoch [1/5], Batch [2000/2951], Loss: 0.8061\n",
      "Epoch [1/5], Batch [2010/2951], Loss: 0.8846\n",
      "Epoch [1/5], Batch [2020/2951], Loss: 0.8468\n",
      "Epoch [1/5], Batch [2030/2951], Loss: 0.4628\n",
      "Epoch [1/5], Batch [2040/2951], Loss: 0.7955\n",
      "Epoch [1/5], Batch [2050/2951], Loss: 0.4389\n",
      "Epoch [1/5], Batch [2060/2951], Loss: 0.8177\n",
      "Epoch [1/5], Batch [2070/2951], Loss: 0.8186\n",
      "Epoch [1/5], Batch [2080/2951], Loss: 0.8102\n",
      "Epoch [1/5], Batch [2090/2951], Loss: 0.6039\n",
      "Epoch [1/5], Batch [2100/2951], Loss: 1.0242\n",
      "Epoch [1/5], Batch [2110/2951], Loss: 1.0477\n",
      "Epoch [1/5], Batch [2120/2951], Loss: 0.7897\n",
      "Epoch [1/5], Batch [2130/2951], Loss: 0.4054\n",
      "Epoch [1/5], Batch [2140/2951], Loss: 0.7960\n",
      "Epoch [1/5], Batch [2150/2951], Loss: 0.5204\n",
      "Epoch [1/5], Batch [2160/2951], Loss: 0.5584\n",
      "Epoch [1/5], Batch [2170/2951], Loss: 0.7766\n",
      "Epoch [1/5], Batch [2180/2951], Loss: 0.8740\n",
      "Epoch [1/5], Batch [2190/2951], Loss: 0.4142\n",
      "Epoch [1/5], Batch [2200/2951], Loss: 0.8207\n",
      "Epoch [1/5], Batch [2210/2951], Loss: 0.4181\n",
      "Epoch [1/5], Batch [2220/2951], Loss: 0.4906\n",
      "Epoch [1/5], Batch [2230/2951], Loss: 0.5308\n",
      "Epoch [1/5], Batch [2240/2951], Loss: 0.8056\n",
      "Epoch [1/5], Batch [2250/2951], Loss: 0.4576\n",
      "Epoch [1/5], Batch [2260/2951], Loss: 0.7659\n",
      "Epoch [1/5], Batch [2270/2951], Loss: 0.7939\n",
      "Epoch [1/5], Batch [2280/2951], Loss: 0.4749\n",
      "Epoch [1/5], Batch [2290/2951], Loss: 0.4090\n",
      "Epoch [1/5], Batch [2300/2951], Loss: 0.7535\n",
      "Epoch [1/5], Batch [2310/2951], Loss: 0.7519\n",
      "Epoch [1/5], Batch [2320/2951], Loss: 0.8929\n",
      "Epoch [1/5], Batch [2330/2951], Loss: 0.7917\n",
      "Epoch [1/5], Batch [2340/2951], Loss: 0.8230\n",
      "Epoch [1/5], Batch [2350/2951], Loss: 0.5246\n",
      "Epoch [1/5], Batch [2360/2951], Loss: 0.3983\n",
      "Epoch [1/5], Batch [2370/2951], Loss: 0.7956\n",
      "Epoch [1/5], Batch [2380/2951], Loss: 0.9883\n",
      "Epoch [1/5], Batch [2390/2951], Loss: 0.8728\n",
      "Epoch [1/5], Batch [2400/2951], Loss: 0.5200\n",
      "Epoch [1/5], Batch [2410/2951], Loss: 0.8991\n",
      "Epoch [1/5], Batch [2420/2951], Loss: 0.5151\n",
      "Epoch [1/5], Batch [2430/2951], Loss: 0.3841\n",
      "Epoch [1/5], Batch [2440/2951], Loss: 0.7965\n",
      "Epoch [1/5], Batch [2450/2951], Loss: 0.5064\n",
      "Epoch [1/5], Batch [2460/2951], Loss: 0.4318\n",
      "Epoch [1/5], Batch [2470/2951], Loss: 0.8330\n",
      "Epoch [1/5], Batch [2480/2951], Loss: 0.9866\n",
      "Epoch [1/5], Batch [2490/2951], Loss: 0.9220\n",
      "Epoch [1/5], Batch [2500/2951], Loss: 0.4479\n",
      "Epoch [1/5], Batch [2510/2951], Loss: 0.8236\n",
      "Epoch [1/5], Batch [2520/2951], Loss: 0.7386\n",
      "Epoch [1/5], Batch [2530/2951], Loss: 0.4316\n",
      "Epoch [1/5], Batch [2540/2951], Loss: 1.1615\n",
      "Epoch [1/5], Batch [2550/2951], Loss: 0.7952\n",
      "Epoch [1/5], Batch [2560/2951], Loss: 0.4882\n",
      "Epoch [1/5], Batch [2570/2951], Loss: 0.8570\n",
      "Epoch [1/5], Batch [2580/2951], Loss: 1.1095\n",
      "Epoch [1/5], Batch [2590/2951], Loss: 0.4056\n",
      "Epoch [1/5], Batch [2600/2951], Loss: 0.3997\n",
      "Epoch [1/5], Batch [2610/2951], Loss: 0.6081\n",
      "Epoch [1/5], Batch [2620/2951], Loss: 0.8958\n",
      "Epoch [1/5], Batch [2630/2951], Loss: 0.7980\n",
      "Epoch [1/5], Batch [2640/2951], Loss: 0.4801\n",
      "Epoch [1/5], Batch [2650/2951], Loss: 0.7924\n",
      "Epoch [1/5], Batch [2660/2951], Loss: 0.8614\n",
      "Epoch [1/5], Batch [2670/2951], Loss: 0.5224\n",
      "Epoch [1/5], Batch [2680/2951], Loss: 0.4115\n",
      "Epoch [1/5], Batch [2690/2951], Loss: 0.5425\n"
     ]
    }
   ],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = LSTMModel().to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     for batch_idx, (videos, labels) in enumerate(dataloader):\n",
    "#         videos, labels = videos.to(device), labels.float().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(videos).squeeze(1)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print(f\"Epoch [{epoch+1}/5], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LSTMModel().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Since sigmoid is removed from model\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    for batch_idx, (videos, labels) in enumerate(dataloader):\n",
    "        videos, labels = videos.to(device), labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(videos).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/5], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = LSTMModel().to(device)\n",
    "# model.apply(init_weights)  # Apply weight initialization\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()  # Since sigmoid is removed from model\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(5):\n",
    "#     for batch_idx, (videos, labels) in enumerate(dataloader):\n",
    "#         videos, labels = videos.to(device), labels.float().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(videos).squeeze(1)\n",
    "        \n",
    "#         # DEBUGGING: Print few outputs\n",
    "#         if batch_idx % 50 == 0:\n",
    "#             print(f\"Raw Model Output (Logits): {outputs[:5].detach().cpu().numpy()}\")\n",
    "        \n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print(f\"Epoch [{epoch+1}/5], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8feb721-5a5f-4e61-b373-1f35e57e65fc",
   "metadata": {},
   "source": [
    "### Model Evaluation (Validation Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325127f4-3d14-4c11-b664-0a72c461ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation on Validation Set\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for videos, labels in val_dataloader:  # Use validation dataloader\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "        outputs = model(videos).squeeze(1)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()  # Convert logits to 0/1\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25ef04-e60c-4383-9617-86a216663a0d",
   "metadata": {},
   "source": [
    "### Testing on New Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6150163-c865-40a6-8ca6-d67964c89bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(video_tensor):\n",
    "    model.eval()\n",
    "    video_tensor = video_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(video_tensor.unsqueeze(0)).squeeze(1)  # Add batch dim\n",
    "        prob = torch.sigmoid(output).item()  # Convert logits to probability\n",
    "        print(f\"Violence Probability: {prob:.4f}\")\n",
    "        return \"Violence Detected\" if prob > 0.5 else \"No Violence\"\n",
    "\n",
    "# Example Test (Ek video tensor input de)\n",
    "video_sample, _ = next(iter(test_dataloader))\n",
    "print(predict_video(video_sample[0]))  # First sample ka prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
